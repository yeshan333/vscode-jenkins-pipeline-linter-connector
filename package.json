{
    "name": "jenkins-pipeline-linter-connector-fork",
    "displayName": "Jenkins Pipeline Linter Connector (fork)",
    "description": "Validate declarative Jenkinsfile syntax in Visual Studio Code. Also support to review Jenkinsfile with LLMs.",
    "version": "2.5.0",
    "icon": "images/icon.png",
    "publisher": "yeshan333",
    "license": "LICENSE.txt",
    "repository": {
        "type": "git",
        "url": "https://github.com/yeshan333/vscode-jenkins-pipeline-linter-connector.git"
    },
    "engines": {
        "vscode": "^1.89.0"
    },
    "categories": [
        "Other"
    ],
    "main": "./out/extension",
    "contributes": {
        "commands": [
            {
                "command": "jenkins.pipeline.linter.connector.validate",
                "title": "Validate Jenkinsfile"
            }
        ],
        "keybindings": [
            {
                "command": "jenkins.pipeline.linter.connector.validate",
                "key": "alt+shift+v",
                "when": "editorFocus"
            }
        ],
        "configuration": {
            "type": "object",
            "title": "Jenkins Pipeline Linter Connector (fork)",
            "properties": {
                "jenkins.pipeline.linter.connector.url": {
                    "type": "string",
                    "description": "the endpoint at which your Jenkins Server expects the POST request, containing your Jenkinsfile which you want to validate. Typically this points to `<your_jenkins_server:port>/pipeline-model-converter/validate`"
                },
                "jenkins.pipeline.linter.connector.user": {
                    "type": "string",
                    "description": "Jenkins username"
                },
                "jenkins.pipeline.linter.connector.pass": {
                    "type": "string",
                    "description": "Jenkins User Password"
                },
                "jenkins.pipeline.linter.connector.token": {
                    "type": "string",
                    "description": "Jenkins user API token."
                },
                "jenkins.pipeline.linter.connector.crumbUrl": {
                    "type": "string",
                    "description": "The url of the crumb service (i.e. http://<your_jenkins_server:port>/crumbIssuer/api/xml/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)"
                },
                "jenkins.pipeline.linter.onsave": {
                    "type": "boolean",
                    "default": false,
                    "description": "lint when Jenkinsfile save"
                },
                "jenkins.pipeline.linter.checkextensions": {
                    "type": "array",
                    "default": [
                        ".jenkinsfile",
                        ".groovy",
                        "Jenkinsfile"
                    ],
                    "description": "Set lint file extension list"
                },
                "jenkins.pipeline.linter.connector.llm.enable": {
                    "type": "boolean",
                    "default": false,
                    "description": "enable linter with LLM"
                },
                "jenkins.pipeline.linter.connector.llm.baseUrl": {
                    "type": "string",
                    "default": "https://api.cloudflare.com/client/v4/accounts/<CF_ACCOUNT_ID>/ai/v1",
                    "description": "LLM openapi base url, eg: https://api.cloudflare.com/client/v4/accounts/<CF_ACCOUNT_ID>/ai/v1"
                },
                "jenkins.pipeline.linter.connector.llm.modelName": {
                    "type": "string",
                    "default": "@cf/meta/llama-2-7b-chat-fp16",
                    "description": "model name, eg: @cf/meta/llama-2-7b-chat-fp16, anyone model in: https://developers.cloudflare.com/workers-ai/models/#text-generation"
                },
                "jenkins.pipeline.linter.connector.llm.apiKey": {
                    "type": "string",
                    "default": "invalid-key",
                    "description": "Cloudflare Worker AI API key (token)."
                },
                "jenkins.pipeline.linter.connector.llm.respLangCode": {
                    "type": "string",
                    "default": "en",
                    "description": "llm response language (lang code), eg: en, zh-hans, ja, ko"
                }
            }
        }
    },
    "scripts": {
        "vscode:prepublish": "npm run package",
        "vscode:buildvsx": "npx @vscode/vsce package",
        "compile": "npm run build",
        "build": "node esbuild.js",
        "watch": "node esbuild.js --watch",
        "package": "node esbuild.js --production",
        "lint": "eslint \"src/**/*.ts\""
    },
    "devDependencies": {
        "@types/node": "^18",
        "@types/vscode": "^1.89.0",
        "@typescript-eslint/eslint-plugin": "^6.7.0",
        "@typescript-eslint/parser": "^6.7.0",
        "esbuild": "^0.25.5",
        "eslint": "^8.26.0",
        "typescript": "^5.4.2"
    },
    "dependencies": {
        "@langchain/openai": "^0.0.33",
        "axios": "^1.6.8",
        "langchain": "^0.2.0",
        "qs": "^6.12.1",
        "web-streams-polyfill": "^4.0.0"
    }
}
